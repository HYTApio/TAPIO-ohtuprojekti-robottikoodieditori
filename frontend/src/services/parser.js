// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
export const parser = LRParser.deserialize({
  version: 14,
  states: "nOQOPOOOOOO'#C^'#C^O#dOPO'#C^QOOOOOOOOO,58x,58x",
  stateData: "%p~OSQOTQOUPOVPOWPOXPOYPOZPO[PO]PO^PO_PO`POaPObPOcPOdPOePOfPOgPOhPOiPOjPOkPOlPOmPOnPOoPOpPOqPOrPOsPOtPOuPOvPOwPO~OUSOVSOWSOXSOYSOZSO[SO]SO^SO_SO`SOaSObSOcSOdSOeSOfSOgSOhSOiSOjSOkSOlSOmSOnSOoSOpSOqSOrSOsSOtSOuSOvSOwSO~O",
  goto: "VRPPSRRO",
  nodeNames: "âš  Program Keyword",
  maxTerm: 39,
  skippedNodes: [0],
  repeatNodeCount: 0,
  tokenData: "3k~R_YZ!Qpq!V#T#U![#U#V!s#X#Y#|#Y#Z${#]#^&Q#^#_&w#`#a'Y#a#b(w#c#d)z#f#g,g#g#h.v#h#i/_#j#k1p~!VOT~~![OS~~!_P#b#c!b~!eP#b#c!h~!kP#T#U!n~!sOf~~!vQ#T#U!|#_#`#w~#PP#V#W#S~#VP#_#`#Y~#]P#k#l#`~#cP#T#U#f~#iP#f#g#l~#oP#W#X#r~#wOj~~#|Ok~~$PQ#b#c$V#h#i$b~$YP#W#X$]~$bOt~~$gPW~#X#Y$j~$mP#X#Y$p~$sP#b#c$v~${OV~~%OQ#W#X%U#c#d%Z~%ZOi~~%^P#f#g%a~%fPv~#k#l%i~%lP#T#U%o~%rP#f#g%u~%xP#W#X%{~&QOh~~&TP#Y#Z&W~&]Pp~#X#Y&`~&cP#`#a&f~&iP#g#h&l~&oP#X#Y&r~&wOq~~&zP#c#d&}~'QP#g#h'T~'YO_~~']R#X#Y'f#h#i'w#i#j'|~'iP#Y#Z'l~'oP#h#i'r~'wOl~~'|Om~~(PP#j#k(S~(VP#i#j(Y~(]P#]#^(`~(cP#`#a(f~(iP#`#a(l~(oP#X#Y(r~(wOe~~(zQ#T#U)Q#]#^)c~)TP#_#`)W~)ZP#X#Y)^~)cOr~~)fP#h#i)i~)lP#X#Y)o~)rP#b#c)u~)zOb~~)}R#]#^*W#`#a+T#i#j+r~*]P^~#_#`*`~*cP#X#Y*f~*iP#T#U*l~*oP#`#a*r~*uP#`#a*x~*{P#X#Y+O~+TO]~~+WP#_#`+Z~+^P#c#d+a~+dP#c#d+g~+jP#b#c+m~+rOa~~+uP#h#i+x~+{P#d#e,O~,RP#i#j,U~,XP#h#i,[~,_Ppq,b~,gOw~~,jR#X#Y,s#]#^-b#h#i.q~,vP#d#e,y~,|P#X#Y-P~-SP#T#U-V~-YP#h#i-]~-bOu~~-eQ#Z#[-k#]#^-|~-nP#[#]-q~-tP#h#i-w~-|On~~.PP#d#e.S~.VP#d#e.Y~.]P#i#j.`~.cP#X#Y.f~.iP#b#c.l~.qO`~~.vOo~~.yP#[#].|~/PP#c#d/S~/VP#k#l/Y~/_Og~~/bR#T#U/k#c#d0[#i#j0{~/pPY~#T#U/s~/vP#_#`/y~/|P#g#h0P~0SP#X#Y0V~0[OX~~0aPs~#]#^0d~0gP#g#h0j~0mP#h#i0p~0sP#T#U0v~0{Od~~1OP#`#a1R~1UP#c#d1X~1[P#g#h1_~1bP#h#i1e~1hP#T#U1k~1pOU~~1sP#T#U1v~1{Q[~#`#a2R#g#h2j~2UP#a#b2X~2[P#]#^2_~2bP#g#h2e~2jOc~~2mP#X#Y2p~2sP#a#b2v~2yP#a#b2|~3PP#T#U3S~3VP#`#a3Y~3]P#`#a3`~3cP#X#Y3f~3kOZ~",
  tokenizers: [0],
  topRules: {"Program":[0,1]},
  tokenPrec: 0
})
